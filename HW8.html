<!DOCTYPE HTML>
<!--
	Read Only by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Read Only by HTML5 UP</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
        <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
        <script>
            window.MathJax = {
                tex: { inlineMath: [['$','$'], ['\\(','\\)']], displayMath: [['$$','$$'], ['\\[','\\]']] },
                svg: { fontCache: 'global' }
            };
        </script>
        <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js"></script>
        <script src="https://cdn.jsdelivr.net/npm/chartjs-plugin-zoom@2.0.1/dist/chartjs-plugin-zoom.min.js"></script>
        <style>
        body {
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif;
            line-height: 1.6;
            background-color: #f8f9fa;
            color: #212529;
            margin: 0;
            padding: 0;
        }
        .container {
            max-width: 800px;
            margin: 20px auto;
            padding: 25px;
            background-color: #ffffff;
            border-radius: 8px;
            box-shadow: 0 2px 8px rgba(0,0,0,0.05);
        }
        h1, h2, h3 {
            color: #343a40;
            line-height: 1.3;
        }
        h1 {
            border-bottom: 2px solid #dee2e6;
            padding-bottom: 10px;
        }
        h2 {
            border-top: 1px solid #eee;
            padding-top: 20px;
            margin-top: 30px;
        }
        code, tt {
            background-color: #e9ecef;
            padding: 3px 6px;
            border-radius: 4px;
            font-family: "Courier New", Courier, monospace;
        }
        blockquote {
            border-left: 4px solid #007bff;
            padding-left: 15px;
            margin-left: 0;
            font-style: italic;
            color: #495057;
        }
    </style>
	</head>
	<body class="is-preload">

		<!-- Header -->
			<section id="header">
				<header>
					<span class="image avatar"><img src="images/avatar.jpg" alt="" /></span>
					<h1 id="logo"><a href="#">Alessio Mareschi</a></h1>
					<p><a href="index.html">Home</a></p>
					
				</header>
				
				<footer>
					<ul class="icons">
						<li><a href="#" class="icon brands fa-twitter"><span class="label">Twitter</span></a></li>
						<li><a href="#" class="icon brands fa-facebook-f"><span class="label">Facebook</span></a></li>
						<li><a href="#" class="icon brands fa-instagram"><span class="label">Instagram</span></a></li>
						<li><a href="#" class="icon brands fa-github"><span class="label">Github</span></a></li>
						<li><a href="#" class="icon solid fa-envelope"><span class="label">Email</span></a></li>
					</ul>
				</footer>
			</section>

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Main -->
					<div id="main">

						<!-- One -->
							<section id="one">
								<div class="image main" data-position="center">
									<img src="images/HW1_image.png" alt="" />
								</div>
								<div class="container">
									<header class="major">
										<h2>Homework 8</h2>
										<p>Theoretical Analysis of the Random Walk Simulation </p>
									</header>
								</div>
							</section>

							<!-- Two -->
							<section id="two">
                                
								<div class="container"> 



        <h2>Mathematical Discussion: Analogies with the Bernoulli LLN Simulation</h2>

        <p>
            This analysis contrasts the current server-security (random-walk) assignment with the previous one, which demonstrated the Law of Large Numbers (LLN) via a Bernoulli process. While both exercises involve simulating independent trials and using success counts to form empirical distributions, they diverge in their outcome mapping and in the definition of a single trial's success probability.
        </p>

        <h3>Common Ground: Bernoulli Trials and Binomial Counts</h3>
        <p>
            The foundation for both problems is the independent Bernoulli trial. In the standard LLN exercise, a trial succeeds with probability $p$, leading to a total success count $K \sim \mathrm{Binomial}(n,p)$ after $n$ trials. In the server-week model, a week is only "secure" if all $m$ attackers fail. The resulting weekly probability of security is
            $$q=(1-p)^m,$$
            and consequently, the total number of secure weeks $K$ is distributed as $\mathrm{Binomial}(n,q)$. The final score, used for the random-walk parallel, is
            $$S = 2K - n,$$
            which linearly transforms the binomial count $K\in\{0,1,\dots,n\}$ to the score space $S\in\{-n,-n+2,\dots,n\}$.
        </p>

        <h3>The PMF, Binomial Coefficients, and Pascal's Triangle</h3>
        <p>
            The binomial probability mass function (PMF) is constructed using binomial coefficients:
            $$\mathbb{P}(K=k)=\binom{n}{k}q^{k}(1-q)^{n-k},\qquad k=0,\dots,n.$$
            In combinatorial terms, $\binom{n}{k}$ is the count of all length-$n$ sequences (trajectories) that contain exactly $k$ secure weeks. Pascal's triangle provides a visual layout of these coefficients: the $n$-th row lists $\binom{n}{0},\binom{n}{1},\dots,\binom{n}{n}$, where every entry is the sum of the two entries directly above it.
        </p>

        <h3>The Binomial Expansion and Normalization</h3>
        <p>
            The binomial theorem provides the reason why the PMF probabilities sum to 1. The theorem states that for any $a,b$,
            $$(a+b)^n=\sum_{k=0}^n \binom{n}{k} a^{n-k} b^k.$$
            By substituting $a=1-q$ and $b=q$, the equation becomes
            $$1=(q + (1-q))^n = \sum_{k=0}^n \binom{n}{k} q^k (1-q)^{n-k},$$
            which demonstrates that the sum of all probabilities in the $\mathrm{Binomial}(n,q)$ distribution is 1, confirming its correct normalization.
        </p>

        <h3>The Random-Walk Perspective and Linear Transforms</h3>
        <p>
            The transformation $K\mapsto S=2K-n$ re-maps the binomial distribution onto a symmetric grid (a lattice) of possible scores. The statistics also transform linearly. We know that:
            $$\mathbb{E}[K]=nq,\qquad \mathrm{Var}(K)=nq(1-q),$$
            This leads to:
            $$\mathbb{E}[S]=2\mathbb{E}[K]-n = n(2q-1),\qquad \mathrm{Var}(S)=4\,\mathrm{Var}(K)=4nq(1-q).$$
            As $n$ grows large, the Central Limit Theorem (CLT) states that the standardized version of $K$ (and therefore $S$) approaches a normal distribution. This is the reason why our simulation histograms take on a bell shape, even for moderately large $n$.
        </p>

        <h3>Contrasts and Parallels with the LLN Simulation</h3>
        <ul>
            <li>Parallel: Both exercises are rooted in a large number of independent trials and use binomial combinatorics to estimate probabilities. Both also demonstrate the LLN principle: empirical frequencies converge to theoretical probabilities over time.</li>
            <li>Contrast: The prior LLN simulation modeled a basic Bernoulli($p$) trial directly (one trial = one success/failure). In this homework, a single trial (one week) is a <strong>composite event</strong> (security requires all $m$ attackers to fail). This makes the effective weekly success probability $q=(1-p)^m$ a non-linear function of $m$ and $p$.</li>
            <li>Contrast in Focus: The LLN experiment centers on the <strong>relative frequency</strong> $K/n$ and its convergence to $p$. The random-walk assignment centers on the <strong>cumulative sum</strong> of $\pm1$ steps (which is a linear transform of $K$) and is more naturally viewed as a path or trajectory.</li>
        </ul>

        <h3>Combinatorial Identities and the Fibonacci Link</h3>
        <p>
            Aside from the primary binomial facts, elegant combinatorial relationships connect Pascal's triangle to other integer sequences, most famously the Fibonacci numbers. A well-known identity states that summing the "shallow diagonals" of the triangle yields the Fibonacci sequence. Formally,
            $$F_n = \sum_{k\ge 0} \binom{n-1-k}{k},$$
            where $F_n$ is the $n$-th Fibonacci number (given appropriate indexing). This property can be proven using induction or via combinatorial arguments (like tiling with squares and dominoes).
        </p>
        <p>
            A separate, powerful identity is Vandermonde's convolution, which involves sums of products of coefficients and is useful when combining independent binomial random variables:
            $$\sum_{k} \binom{r}{k}\binom{s}{n-k}=\binom{r+s}{n}.$$
            This identity is particularly useful when decomposing an experiment into multiple stages (e.g., conditioning on the breach count in the first half of the weeks).
        </p>

        <h3>Practical Takeaways and Further Experiments</h3>
        <ul>
            <li>Vary $m$ and $p$ (holding $n$ constant) to see how the effective probability $q=(1-p)^m$ alters the histogram's shape and the mean of the final score $S$. A small $q$ will skew the distribution toward negative scores, while $q\approx 0.5$ will center the distribution near $S=0$.</li>
            <li>Check the empirical frequencies from the simulation against the theoretical $\mathrm{Binomial}(n,q)$ PMF. Plot the absolute error (difference) against $T$ (the total number of trajectories) to visualize the $O(1/\sqrt{T})$ convergence rate associated with the LLN.</li>
            <li>Calculate the distribution's cumulants. The formulas for binomial skewness and kurtosis demonstrate how the distribution deviates from a perfect normal curve at small $n$. Observe how these values approach the Gaussian limits as $n$ increases.</li>
        </ul>

        <h3>Conclusion</h3>
        <p>
            In conclusion, both assignments serve as practical investigations into the same fundamental concepts: independent Bernoulli trials and binomial combinatorics. The random-walk framing re-casts the binomial counts onto a symmetric score lattice, focusing on the sum, while the LLN experiment highlights the convergence of the mean. The precise combinatorial framework is provided by Pascal's triangle, binomial coefficients, and the binomial theorem. Furthermore, deeper identities, like the one linking to Fibonacci numbers or Vandermonde's convolution, showcase the broad and elegant connections between probability, algebra, and discrete mathematics.
        </p>
    </div>

                              


								


							</section>

						
						<!-- Three -->
							

						

						

					</div>

				<!-- Footer -->
					<section id="footer">
						<div class="container">
							<ul class="copyright">
								<li>&copy; Untitled. All rights reserved.</li><li>Design: <a href="http://html5up.net">HTML5 UP</a></li>
							</ul>
						</div>
					</section>

			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>